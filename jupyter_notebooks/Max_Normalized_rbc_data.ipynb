{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (1.16.4)\n",
      "Collecting pims\n",
      "  Using cached https://files.pythonhosted.org/packages/00/08/bbf9f5465c92ea6577bc5824fea21d2583e24e94fe10cc853587ffcacda0/PIMS-0.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.7 in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (from pims) (1.16.4)\n",
      "Collecting slicerator>=0.9.7 (from pims)\n",
      "  Using cached https://files.pythonhosted.org/packages/75/ae/fe46f5371105508a209fe6162e7e7b11db531a79d2eabcd24566b8b1f534/slicerator-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.8 in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (from pims) (1.12.0)\n",
      "Installing collected packages: slicerator, pims\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/common/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages/slicerator-1.0.0.dist-info'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "Requirement already satisfied: netCDF4 in /global/u1/r/rgupta2/.local/cori/intel-tensorflow1.13.1-py36/lib/python3.6/site-packages (1.5.1.2)\n",
      "Requirement already satisfied: cftime in /global/u1/r/rgupta2/.local/cori/intel-tensorflow1.13.1-py36/lib/python3.6/site-packages (from netCDF4) (1.0.3.4)\n",
      "Requirement already satisfied: numpy>=1.7 in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (from netCDF4) (1.16.4)\n",
      "Requirement already satisfied: xarray in /global/u1/r/rgupta2/.local/cori/intel-tensorflow1.13.1-py36/lib/python3.6/site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.12 in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (from xarray) (1.16.4)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (from xarray) (0.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (from pandas>=0.19.2->xarray) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (from pandas>=0.19.2->xarray) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas>=0.19.2->xarray) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /global/u1/r/rgupta2/.local/cori/intel-tensorflow1.13.1-py36/lib/python3.6/site-packages (4.32.2)\n",
      "Requirement already satisfied: kornia in /global/u1/r/rgupta2/.local/cori/intel-tensorflow1.13.1-py36/lib/python3.6/site-packages (0.1.3.post2)\n",
      "Requirement already satisfied: torch>=1.0.0 in /global/u1/r/rgupta2/.local/cori/intel-tensorflow1.13.1-py36/lib/python3.6/site-packages (from kornia) (1.2.0)\n",
      "Requirement already satisfied: numpy in /global/common/cori_cle7/software/tensorflow/intel-tensorflow/1.13.1-py36/lib/python3.6/site-packages (from torch>=1.0.0->kornia) (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "#!/bin/env python\n",
    "\n",
    "\n",
    "import sys,os,os.path,time\n",
    "sys.path.append(os.path.expanduser('/global/u1/r/rgupta2/.local/lib/python3.7/site-packages/'))\n",
    "\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pims\n",
    "!{sys.executable} -m pip install --user netCDF4\n",
    "!{sys.executable} -m pip install --user xarray\n",
    "!{sys.executable} -m pip install --user tqdm\n",
    "!{sys.executable} -m pip install --user kornia\n",
    "\n",
    "# export PYTHONPATH=\"${PYTHONPATH}:/usr/local/lib/python2.7/site-packages:/usr/lib/python2.7/site-packages\"\n",
    "import numpy as np\n",
    "import time\n",
    "import torch, kornia\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "# from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "\n",
    "file_path = \"/project/projectdirs/dasrepo/mustafa/datasets/Rayleigh_Benard/result_rb_2d__Ra_2.5e8__Pr_0.71__maxMach_0.1__t_D_max_diffusive_scaling__0.4.nc\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time takes :  163.82600903511047\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "ds = xr.open_dataset(file_path, decode_times=False\t)\n",
    "print(\"Time takes : \", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This block plots the differnet velocity field vectors for considered time range and how normalizing them affects them\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st_time = 10000\n",
    "end_time =15000\n",
    "image_size = 256\n",
    "\n",
    "number_of_timesteps = 500\n",
    "\n",
    "ux_data_for_tke = ds['u_x'][st_time : end_time].values\n",
    "uy_data_for_tke = ds['u_y'][st_time : end_time].values\n",
    "\n",
    "\n",
    "save_dir_path = \"/global/cscratch1/sd/rgupta2/backup/StyleGAN/dataset/\"\n",
    "\n",
    "\n",
    "ux_data_mean_tke = np.mean(ux_data_for_tke, axis = 0)\n",
    "uy_data_mean_tke = np.mean(uy_data_for_tke, axis = 0)\n",
    "\n",
    "print(ux_data_mean_tke.shape)\n",
    "\n",
    "\n",
    "# load_path = os.path.join(dataset_location + \"tke_average_energies.npy\")\n",
    "# my_dict_back = np.load(load_path, allow_pickle=True)\n",
    "# ux_average_over_time = my_dict_back.item()[\"{}_ux\".format(image_size)]\n",
    "# uy_average_over_time = my_dict_back.item()[\"{}_uy\".format(image_size)]\n",
    "\n",
    "# print(ux_data_for_tke.shape)\n",
    "# print(uy_data_for_tke.shape)\n",
    "\n",
    "res_list = [8, 16, 32, 64, 128, 256]\n",
    "tt = time.time()\n",
    "Data = {}\n",
    "for res in res_list:\n",
    "    print(ux_data_mean_tke.shape)\n",
    "    print(\"Time taken to complete iteration\", time.time() - tt)\n",
    "    \n",
    "    \n",
    "    ux_data = ux_data_mean_tke\n",
    "    \n",
    "    strides_x =  [x * ux_data.itemsize for x in [ux_data.shape[-1] * ux_data.shape[-2], res, ux_data.shape[-1], 1]]\n",
    "    u_x = np.lib.stride_tricks.as_strided(ux_data, (number_of_timesteps, ux_data.shape[-1]//image_size, image_size, image_size), strides_x)\n",
    "\n",
    "    ux_data_mean_tke = np.mean(u_x, axis=0)\n",
    "    \n",
    "    print(\" strides : {} u_x.shape {} ux_data_mean_tke : {} \".format(strides, u_x.shape, ux_data_mean_tke.shape))\n",
    "    \n",
    "    \n",
    "    \n",
    "    uy_data = uy_data_mean_tke\n",
    "\n",
    "    strides_y =  [x * uy_data.itemsize for x in [uy_data.shape[-1] * uy_data.shape[-2], image_size, uy_data.shape[-1], 1]]\n",
    "    u_y = np.lib.stride_tricks.as_strided(uy_data, (number_of_timesteps, ux_data.shape[-1]//image_size, image_size, image_size), strides_y)\n",
    "    uy_data_mean_tke = np.mean(u_y, axis=0)\n",
    "    \n",
    "    print(\"u_y.shape {}, uy_data_mean_tke {} \".format(u_y.shape, uy_data_mean_tke.shape))\n",
    "    \n",
    "    \n",
    "    \n",
    "    Data[\"{}_ux\".format(res)] = ux_data_mean_tke\n",
    "    Data[\"{}_uy\".format(res)] = uy_data_mean_tke\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "save_path = os.path.join(save_dir_path , \"rbc_{}/std_normalized/\".format(number_of_timesteps))\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "np.save( str(save_path) + \"tke_average_energies_{}_{}.npy\".format(st_time, end_time), Data)\n",
    "    \n",
    "print(\"Time taken to complete iteration\", time.time() - tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 2, 256, 256)\n",
      "(3500, 2, 256, 256)\n",
      "(3500, 2, 256, 256)\n",
      "(3500, 2, 256, 256)\n",
      "(3500, 2, 256, 256)\n",
      "(3500, 2, 256, 256)\n",
      "(3500, 2, 256, 256)\n",
      "(3500, 2, 256, 256)\n",
      "(3500, 2, 256, 256)\n",
      "(3500, 2, 256, 256)\n",
      "(256, 256)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2bf7ccbfb127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_dir_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"tke_average_energies_{}.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstored_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken to complete iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tt' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "load_dir_path = \"/global/cscratch1/sd/rgupta2/backup/StyleGAN/dataset/rbc_500/max/\"\n",
    "\n",
    "np_files =  sorted(glob(\"{}/*.npy\".format(load_dir_path)))[:]\n",
    "\n",
    "tmp_ux = []\n",
    "tmp_uy = []\n",
    "\n",
    "for file in np_files:\n",
    "    Data = np.load(file)\n",
    "    print(Data.shape)\n",
    "    tmp_ux.append(Data[:,0,:,:])\n",
    "    tmp_uy.append(Data[:,1,:,:])\n",
    "    \n",
    "\n",
    "ux_data_for_tke = np.concatenate(tmp_ux, axis=0)\n",
    "uy_data_for_tke = np.concatenate(tmp_uy, axis=0)\n",
    "\n",
    "ux_data_mean_tke = np.mean(ux_data_for_tke, axis = 0)\n",
    "uy_data_mean_tke = np.mean(uy_data_for_tke, axis = 0)\n",
    "\n",
    "print(ux_data_mean_tke.shape)\n",
    "res = ux_data_mean_tke.shape[-1]\n",
    "\n",
    "\n",
    "stored_data = {}\n",
    "\n",
    "stored_data[\"{}_ux\".format(res)] = ux_data_mean_tke\n",
    "stored_data[\"{}_uy\".format(res)] = uy_data_mean_tke\n",
    "\n",
    "np.save( str(load_dir_path) + \"tke_average_energies_{}.npy\".format(res), stored_data)\n",
    "    \n",
    "print(\"Time taken to complete iteration\", time.time() - tt)\n",
    "\n",
    "\n",
    "# load_path = os.path.join(dataset_location + \"tke_average_energies.npy\")\n",
    "# my_dict_back = np.load(load_path, allow_pickle=True)\n",
    "# ux_average_over_time = my_dict_back.item()[\"{}_ux\".format(image_size)]\n",
    "# uy_average_over_time = my_dict_back.item()[\"{}_uy\".format(image_size)]\n",
    "\n",
    "# print(ux_data_for_tke.shape)\n",
    "# print(uy_data_for_tke.shape)\n",
    "\n",
    "# res_list = [8, 16, 32, 64, 128, 256]\n",
    "# tt = time.time()\n",
    "# Data = {}\n",
    "# for res in res_list:\n",
    "#     print(ux_data_mean_tke.shape)\n",
    "#     print(\"Time taken to complete iteration\", time.time() - tt)\n",
    "    \n",
    "    \n",
    "#     ux_data = ux_data_mean_tke\n",
    "    \n",
    "#     strides_x =  [x * ux_data.itemsize for x in [ux_data.shape[-1] * ux_data.shape[-2], res, ux_data.shape[-1], 1]]\n",
    "#     u_x = np.lib.stride_tricks.as_strided(ux_data, (number_of_timesteps, ux_data.shape[-1]//image_size, image_size, image_size), strides_x)\n",
    "\n",
    "#     ux_data_mean_tke = np.mean(u_x, axis=0)\n",
    "    \n",
    "#     print(\" strides : {} u_x.shape {} ux_data_mean_tke : {} \".format(strides, u_x.shape, ux_data_mean_tke.shape))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     uy_data = uy_data_mean_tke\n",
    "\n",
    "#     strides_y =  [x * uy_data.itemsize for x in [uy_data.shape[-1] * uy_data.shape[-2], image_size, uy_data.shape[-1], 1]]\n",
    "#     u_y = np.lib.stride_tricks.as_strided(uy_data, (number_of_timesteps, ux_data.shape[-1]//image_size, image_size, image_size), strides_y)\n",
    "#     uy_data_mean_tke = np.mean(u_y, axis=0)\n",
    "    \n",
    "#     print(\"u_y.shape {}, uy_data_mean_tke {} \".format(u_y.shape, uy_data_mean_tke.shape))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     Data[\"{}_ux\".format(res)] = ux_data_mean_tke\n",
    "#     Data[\"{}_uy\".format(res)] = uy_data_mean_tke\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-intel(cpu)/1.13.1-py36 [conda env:root] *",
   "language": "python",
   "name": "conda-root-tensorflow_intel_1.13.1_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
